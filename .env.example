# ┌──────────────────────────────────────────────────────────────┐
# │            .env.example  —  copy to .env & edit             │
# └──────────────────────────────────────────────────────────────┘
#
#  DATA SOURCES
#  ─────────────
#    • supabase   → pgvector + SQL
#    • fmp        → Financial Modeling Prep REST API
#
#  LLM BACK-ENDS (choose at runtime)
#    • http   → local Ollama, vLLM, LM Studio … (OpenAI-spec URL)
#    • openai → real OpenAI / Groq / Together / Fireworks
# -----------------------------------------------------------------

#########################
# Data-source selector
#########################
DATA_SOURCE=supabase          # supabase | fmp

#########################
# Supabase credentials
#########################
SUPABASE_URL=https://YOUR-PROJECT.supabase.co
SUPABASE_SERVICE_KEY=sk_********************************
SUPABASE_DB_URL=postgresql://postgres:PASSWORD@db.x.supabase.co:5432/postgres
SUPABASE_BUCKET=chatbot-outputs

#########################
# Financial Modeling Prep
#########################
FMP_API_KEY=demo-********************************
FMP_BASE_URL=https://financialmodelingprep.com/api/v3

#########################
# LLM provider selector
#########################
LLM_PROVIDER=http             # http | openai

# ---  If LLM_PROVIDER=http  (local Ollama)  ---------------------
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_MODEL=llama3:8b        # whatever tag you pulled
# OPENAI_API_KEY=             # leave blank (Ollama ignores)

# ---  If LLM_PROVIDER=openai (cloud)  ---------------------------
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o
# OPENAI_API_KEY=sk-********************************

#########################
# Generation defaults
#########################
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024

#########################
# Server settings
#########################
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info
